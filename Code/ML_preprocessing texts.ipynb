{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "from geotext import GeoText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found directory: ../Data/\n",
      "../Data/\n",
      "Found directory: ../Data/PE2008\n",
      "../Data/PE2008\n",
      "Found directory: ../Data/PE2012\n",
      "../Data/PE2012\n",
      "Found directory: ../Data/PE2016\n",
      "../Data/PE2016\n"
     ]
    }
   ],
   "source": [
    "rootDir = '../Data/'\n",
    "\n",
    "#for dirName, subdirList, fileList in os.walk(rootDir) :\n",
    "\n",
    "d = {}\n",
    "#c = 0\n",
    "remarkls = []\n",
    "interviewls = []\n",
    "questionls = []\n",
    "otherls = []\n",
    "speechls = []\n",
    "addressls = []\n",
    "r = 0\n",
    "i = 0\n",
    "q = 0\n",
    "o = 0\n",
    "s = 0\n",
    "#statement_num = 0\n",
    "pe_dict = {2008:{}, 2012:{}, 2016:{}}\n",
    "for dirName, subdirList, fileList in os.walk(rootDir) :\n",
    "    print('Found directory: %s' % dirName)\n",
    "    print(dirName)\n",
    "    c = 0\n",
    "    for fname in fileList:        \n",
    "        if fname.endswith(\".txt\"):  \n",
    "            filepath = os.path.join(dirName, fname)\n",
    "            if dirName == '../Data/PE2008':  \n",
    "                c += 1\n",
    "                year = 2008\n",
    "                d = pe_dict[year]\n",
    "                speaker = fname[8:-4]\n",
    "            else:\n",
    "                c += 1\n",
    "                year = fname[8:12]\n",
    "                d = pe_dict[int(year)]\n",
    "                speaker = fname[12:-4]\n",
    "            d[speaker]={}\n",
    "            with open(filepath, 'r', -1, \"ISO-8859-1\") as input_file:\n",
    "                data = input_file.read()\n",
    "                splited_speeches = data.split('\\n\\n\\n')\n",
    "                statement_num = 0\n",
    "                for i in range(len(splited_speeches)):\n",
    "                    statement_num += 1\n",
    "                    speech = splited_speeches[i]\n",
    "                    text_first = speech.split('\\n')\n",
    "                    text = [item for item in text_first if item != '']\n",
    "                    if text != []:\n",
    "                        title = text[0]\n",
    "                        if 'remarks' in text[0].lower():\n",
    "                            remarkls.append([speaker, title])\n",
    "                            places = GeoText(title)\n",
    "                            city = places.cities\n",
    "                            d[speaker][statement_num] = {'Author': speaker, 'Title': title,\n",
    "                                                   'Year':year, 'Text': text, 'Type': 'remarks', 'City':city}\n",
    "                        elif 'speech' in text[0].lower():\n",
    "                            speechls.append([speaker, title])\n",
    "                            places = GeoText(title)\n",
    "                            city = places.cities\n",
    "                            d[speaker][statement_num] = {'Author': speaker, 'Title': title,\n",
    "                                                   'Year':year, 'Text': text, 'Type': 'speech','City':city}\n",
    "                        elif 'interview' in text[0].lower():\n",
    "                            interviewls.append([speaker, title])\n",
    "                            places = GeoText(title)\n",
    "                            city = places.cities\n",
    "                            d[speaker][statement_num] = {'Author': speaker, 'Title': title,\n",
    "                                                   'Year':year, 'Text': text,'Type': 'interview','City':city }\n",
    "                        elif ('question' or 'q&a') in text[0].lower():\n",
    "                            questionls.append([speaker, title])\n",
    "                            places = GeoText(title)\n",
    "                            city = places.cities\n",
    "                            d[speaker][statement_num] = {'Author': speaker, 'Title': title,\n",
    "                                                   'Year':year, 'Text': text, 'Type': 'question','City':city}\n",
    "                        elif 'address' in text[0].lower():\n",
    "                            addressls.append([speaker, title]) \n",
    "                            places = GeoText(title)\n",
    "                            city = places.cities\n",
    "                            d[speaker][statement_num] = {'Author': speaker, 'Title': title,\n",
    "                                                   'Year':year, 'Text': text, 'Type': 'address','City':city}\n",
    "                        else:\n",
    "                            otherls.append([speaker, title])\n",
    "                            places = GeoText(title)\n",
    "                            city = places.cities\n",
    "                            d[speaker][statement_num] = {'Author': speaker, 'Title': title,\n",
    "                                                   'Year':year, 'Text': text, 'Type': 'others','City':city}\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "20words \n",
    "1. free trade agreeement, free trade 2. liberalization, liberalize 3. labor, labor union\n",
    "4. export 5. grow, growth 6. manufacturing 7. world 8. subsidy 9. protect, protection \n",
    "10. economy 11. China 12. import 13. competition, compete 14. rust belt 15. Mexico \n",
    "16. cheap 17. unemploy, unemployment 18. adjustment, adjust 19. WTO, NAFTA 20. dumping, anti-dumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([2008, 2016, 2012])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe_dict[2008]['Barack Obama'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Selma']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe_dict[2008]['Barack Obama'][4]['City']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1069\n",
      "178\n",
      "2\n",
      "17\n",
      "53\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "print(len(remarkls))\n",
    "print(len(interviewls))\n",
    "print(len(questionls))\n",
    "print(len(otherls))\n",
    "print(len(speechls))\n",
    "print(len(addressls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from geotext import GeoText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geograpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Remarks to the Republican National Convention in Cleveland, Ohio'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "placetext = geograpy.Extractor(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<geograpy.extraction.Extractor at 0x121026a20>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placetext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
