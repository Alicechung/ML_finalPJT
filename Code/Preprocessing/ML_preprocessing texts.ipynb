{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_wordsls = ['free trade agreeement','free trade' ,'liberalization', 'liberalize' 'labor', 'labor union',\n",
    "'export', 'grow', 'growth', 'manufacturing', 'world','subsidy', 'protect', 'protection', \n",
    "'economy', 'china','import', 'competition', 'compete', 'rust belt','mexico', \n",
    "'cheap', 'unemploy', 'unemployment', 'adjustment', 'adjust' ,'wto', 'nafta', 'dumping', 'anti-dumping',\n",
    "'trade','unfair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rustbelts = ['New York', 'Pennsylvania', 'West Virginia', 'Ohio', 'Indiana', 'Michigan',\n",
    "             'Illinois', 'Iowa', 'Wisconsin', 'Missouri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rustbelts_ex = ['Pennsylvania', 'West Virginia', 'Ohio', 'Indiana', 'Michigan',\n",
    "             'Illinois', 'Iowa', 'Wisconsin', 'Missouri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dem = ['Barack Obama', 'Hillary Clinton', 'John Edwards', 'Bill Richardson',\n",
    "      'Christopher Dodd', 'Joe Biden', 'Bernie Sanders',  \"Martin O'Malley\", \n",
    "      'Lincoln Chafee', 'Jim Webb']\n",
    "\n",
    "rep = ['John McCain', 'Mike Huckabee', 'Mitt Romney', 'Rudy Giuliani',\n",
    "      'Fred Thompson', 'Ron Paul', 'Newt Gingrich', 'Rick Santorum', 'Rick Perry',\n",
    "      'Jon Huntsman', 'Michele Bachmann', 'Herman Cain', 'Tim Pawlenty',\n",
    "       'Donald J. Trump', 'John Kasich', 'Ted Cruz', 'Marco Rubio', 'Ben Carson',\n",
    "      'Jeb Bush', 'Chris Christie', 'Carly Fiorina', 'Rand Paul', 'George Pataki',\n",
    "      'Lindsey Graham','Scott Walker', 'Bobby Jindal',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found directory: ../Data/\n",
      "../Data/\n",
      "Found directory: ../Data/cb_2016_us_state_20m\n",
      "../Data/cb_2016_us_state_20m\n",
      "Found directory: ../Data/PE2008\n",
      "../Data/PE2008\n",
      "Found directory: ../Data/PE2012\n",
      "../Data/PE2012\n",
      "Found directory: ../Data/PE2016\n",
      "../Data/PE2016\n"
     ]
    }
   ],
   "source": [
    "rootDir = '../Data/'\n",
    "\n",
    "d = {}\n",
    "remarkls = []\n",
    "interviewls = []\n",
    "questionls = []\n",
    "otherls = []\n",
    "speechls = []\n",
    "addressls = []\n",
    "r = 0\n",
    "i = 0\n",
    "q = 0\n",
    "o = 0\n",
    "s = 0\n",
    "fdls = []\n",
    "pe_dict = {2008:{}, 2012:{}, 2016:{}}\n",
    "for dirName, subdirList, fileList in os.walk(rootDir) :\n",
    "    print('Found directory: %s' % dirName)\n",
    "    print(dirName)\n",
    "    c = 0\n",
    "    for fname in fileList:        \n",
    "        if fname.endswith(\".txt\"):  \n",
    "            filepath = os.path.join(dirName, fname)\n",
    "            if dirName == '../Data/PE2008':  \n",
    "                c += 1\n",
    "                year = 2008\n",
    "                d = pe_dict[year]\n",
    "                speaker = fname[8:-4]\n",
    "            else:\n",
    "                c += 1\n",
    "                year = fname[8:12]\n",
    "                d = pe_dict[int(year)]\n",
    "                speaker = fname[12:-4]\n",
    "            if speaker in dem:\n",
    "                partyid = 'Dem'\n",
    "            if speaker in rep:\n",
    "                partyid = 'Rep'\n",
    "            d[speaker]={}\n",
    "            with open(filepath, 'r', -1, \"ISO-8859-1\") as input_file:\n",
    "                data = input_file.read()\n",
    "                splited_speeches = data.split('\\n\\n\\n')\n",
    "                #print(splited_speeches)\n",
    "                statement_num = 0\n",
    "                for i in range(len(splited_speeches)):\n",
    "                    statement_num += 1\n",
    "                    one_speech = re.sub(r'\\((?!k\\))(.*?)\\)', '', splited_speeches[i], flags= re.IGNORECASE)\n",
    "                    one_speech_fin = re.sub(r'\\[(.*?)\\]', '', one_speech) \n",
    "                    t = one_speech_fin.replace('\\x80\\x94','').replace('\\x80','').replace('\\x94','').split('\\n')\n",
    "                    text = [item for item in t if item != '' if not item.startswith('To view')\\\n",
    "                            if not item.startswith('Citation:')]\n",
    "                    whole_text = \" \".join(text[2:])     \n",
    "                    #whole_text5 = re.sub(r'[^\\w\\s]', '',whole_text31.lower())\n",
    "                    tokens = nltk.tokenize.word_tokenize(whole_text.lower())\n",
    "                    punc = [re.sub(r'[^\\w]', '', word.lower()) for word in stops]\n",
    "                    whole_text4 = [word for word in tokens if word.lower() not in punc]\n",
    "                    fd = nltk.FreqDist(whole_text4)\n",
    "                    if text != []:\n",
    "                        title = text[0]\n",
    "                        dateobj = datetime.datetime.strptime(text[1], '%B %d, %Y')\n",
    "                        remarkls.append([speaker, title])\n",
    "                        if 'remarks' in text[0].lower():\n",
    "                            remarkls.append([speaker, title])\n",
    "                            ttype = 'remarks'\n",
    "                        elif 'speech' in text[0].lower():\n",
    "                            speechls.append([speaker, title])\n",
    "                            ttype = 'speech'\n",
    "                        elif 'interview' in text[0].lower():\n",
    "                            interviewls.append([speaker, title])\n",
    "                            ttype = 'interview'\n",
    "                        elif ('question' or 'q&a') in text[0].lower():\n",
    "                            questionls.append([speaker, title])\n",
    "                            ttype = 'question'\n",
    "                        elif 'address' in text[0].lower():\n",
    "                            addressls.append([speaker, title]) \n",
    "                            ttype = 'address'\n",
    "                        else:\n",
    "                            otherls.append([speaker, title])\n",
    "                            ttype = 'others'\n",
    "                                                \n",
    "                        d[speaker][statement_num] = {'Author': speaker, 'Title': title,\n",
    "                                                    'Year':year, 'Whole':splited_speeches[i],\n",
    "                                                     'Clean': whole_text,\n",
    "                                                     'Text': text,\n",
    "                                                     'Date':dateobj,\n",
    "                                                    'Type': ttype,#'City':city,\n",
    "                                                     'PartyID':partyid}\n",
    "                                                    #'Geocity': cname,'State': state}\n",
    "                        fdls.append(fd.most_common(10))               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#re.sub(r'\\[(.*?)\\]' , '','Thank you. (APPLAUS) (APPLAUSE AND CHEERS) [applause] Thank you. [applause] (k) (applause and cheers) [apple and bo] (cheers, applause.).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "swing  = pd.read_excel('../Data/swingstate_2008-2016.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#re.findall(r'\\((?!k\\))\\w+\\)', '(k) i am, us dep economy (applause) (ph) (APPLAUSE)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp = {}\n",
    "for year1, values1 in pe_dict.items():\n",
    "    for author1, values2 in values1.items():\n",
    "        for number, values3 in values2.items():\n",
    "            #print(values3)\n",
    "            temp.setdefault('Year1', []).append(year1)\n",
    "            temp.setdefault('Author1', []).append(author1)\n",
    "            temp.setdefault('No.', []).append(number)\n",
    "            for key, value in values3.items():\n",
    "                temp.setdefault(key, []).append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "pt = PorterStemmer()\n",
    "\n",
    "from nltk import trigrams\n",
    "from nltk import word_tokenize\n",
    "import re, os\n",
    "\n",
    "stemmed_stop = list(map(pt.stem , stop_words))\n",
    "stemmed_stop = list(map(lambda x: re.sub('\\W', '', x), stop_words))\n",
    "\n",
    "\n",
    "for  z in statements:\n",
    "\ttexts = word_tokenize(re.sub('\\W', ' ', z[1].lower()))\n",
    "\ttexts2 = map(pt.stem, texts)\n",
    "\ttexts3 = [x for x in texts2 if x not in stemmed_stop]\n",
    "\ttemp_tri = trigrams(texts3)\n",
    "\tfor l in texts3:\n",
    "\t\tif l in uni_dict:\n",
    "\t\t\tuni_dict[l]+=1\n",
    "\t\tif l not in uni_dict:\n",
    "\t\t\tuni_dict[l] = 1\n",
    "\tfor n in temp_tri:\n",
    "\t\tif n in tri_dict:\n",
    "\t\t\ttri_dict[n]+=1 \n",
    "\t\tif n not in tri_dict:\n",
    "\t\t\ttri_dict[n] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df08 = df[df['Year1'] == 2008]\n",
    "df12 = df[df['Year1'] == 2012]\n",
    "df16 = df[df['Year1'] == 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f08 = df08[(datetime.datetime(2005, 1, 1, 0, 0) <= df08['Date']) \\\n",
    "           & (df08['Date'] <= datetime.datetime(2008, 12, 31, 0, 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f12 = df12[(datetime.datetime(2009, 1, 1, 0, 0) <= df12['Date']) \\\n",
    "           & (df12['Date'] <= datetime.datetime(2012, 12, 31, 0, 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f16 = df16[(datetime.datetime(2013, 1, 1, 0, 0) <= df16['Date']) \\\n",
    "           & (df16['Date'] <= datetime.datetime(2016, 12, 31, 0, 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refine = pd.concat([f08,f12,f16]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refine_fin  = refine[['Author', 'Author1', 'Clean', 'Date', 'No.', 'PartyID', 'Text',\n",
    "       'Title', 'Type', 'Whole', 'Year', 'Year1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refine_fin.to_csv('../Data/df_180223.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#statedf = refine[['index', 'Author', 'No.', 'Title', 'Type', 'Year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#statedf.to_csv('df18023_addingstate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdf = pd.read_csv('../Data/df_180223.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Author', 'Author1', 'Clean', 'Date', 'No.', 'PartyID',\n",
       "       'Text', 'Title', 'Type', 'Whole', 'Year', 'Year1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1247, 13)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adddf = pd.read_excel('../Data/df18022_addingstate_afternoon.xlsx', sheet_name='df18022_addingstate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Author', 'No.', 'Title', 'Type', 'Year', 'State', 'Abb'], dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adddf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged = rdf.merge(adddf, left_on=['Author','No.','Year'],\n",
    "                right_on = ['Author','No.','Year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Author', 'Author1', 'Clean', 'Date', 'No.', 'PartyID',\n",
       "       'Text', 'Title_x', 'Type_x', 'Whole', 'Year', 'Year1', 'index',\n",
       "       'Title_y', 'Type_y', 'State', 'Abb'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'state', 'swing_last2', 'swing_last', 'average'], dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sw08 = swing[swing['year'] == 2008]\n",
    "sw12 = swing[swing['year'] == 2012]\n",
    "sw16 = swing[swing['year'] == 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addingstatedf = merged[['Unnamed: 0', 'Author', 'Author1', 'Clean', 'Date', 'No.', 'PartyID',\n",
    "                        'State','Abb','Text', 'Title_x', 'Type_x', 'Whole', 'Year', 'Year1', \n",
    "                        'index','Title_y', 'Type_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addstate08 = addingstatedf[addingstatedf['Year1'] == 2008]\n",
    "addstate12 = addingstatedf[addingstatedf['Year1'] == 2012]\n",
    "addstate16 = addingstatedf[addingstatedf['Year1'] == 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldf = pd.concat([addstate08,addstate12,addstate16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statesw08 = alldf.merge(sw08, left_on=['Abb'],right_on = ['state'], how='left')\n",
    "statesw08.rename(columns = {'swing_last':'swing_last_08'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statesw12 = statesw08.merge(sw12, left_on=['Abb'],right_on = ['state'], how='left')\n",
    "statesw12.rename(columns = {'swing_last':'swing_last_12'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statesw16 = statesw12.merge(sw16, left_on=['Abb'],right_on = ['state'], how='left')\n",
    "statesw16.rename(columns = {'swing_last':'swing_last_16'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldf_sw = statesw16[['Year', 'Year1', 'Author', 'Author1', 'Clean', 'Date', 'No.', 'PartyID',\n",
    "       'State', 'Abb', 'Title_x', 'swing_last_08', 'swing_last_12', 'swing_last_16']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misun/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "alldf_sw ['Rustbelt'] = np.where(alldf_sw[\"State\"].isin(rustbelts_ex), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misun/anaconda/lib/python3.5/site-packages/pandas/core/frame.py:3027: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "alldf_sw.rename(columns = {'Title_x':'Title'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Year1', 'Author', 'Author1', 'Clean', 'Date', 'No.', 'PartyID',\n",
       "       'State', 'Abb', 'Title', 'swing_last_08', 'swing_last_12',\n",
       "       'swing_last_16', 'Rustbelt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldf_sw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldf_sw.to_csv('../Data/alldf_180223.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.read_csv('alldf_180223.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(685, 18)\n",
      "(282, 18)\n",
      "(280, 18)\n",
      "(685, 23)\n",
      "(282, 23)\n",
      "(280, 23)\n"
     ]
    }
   ],
   "source": [
    "print(addstate08.shape)\n",
    "print(addstate12.shape)\n",
    "print(addstate16.shape)\n",
    "print(statesw08.shape)\n",
    "print(statesw12.shape)\n",
    "print(statesw16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df1[\"EU\"] = np.where(df1[\"Country\"].isin(EU), \"EU\", \"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ny.to_csv('NY_sate_180223.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#findf = addingstatedf[['Year', 'Year1','Author', 'Author1','Date', 'No.',\n",
    "#!               'PartyID', 'State', 'Clean','Title_x', 'Whole']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#findf.to_csv('../Data/df_final_180223.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rust10 = findf[findf['State'].isin(rustbelts_ex)][['Author','Year1','No.','Date',\n",
    "                                                'PartyID','State','Clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rust10_not = findf[~findf['State'].isin(rustbelts_ex)][['Author','Year1','No.','Date',\n",
    "                                                        'PartyID','State','Clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>No.</th>\n",
       "      <th>Date</th>\n",
       "      <th>PartyID</th>\n",
       "      <th>State</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>510</td>\n",
       "      <td>510</td>\n",
       "      <td>510</td>\n",
       "      <td>510</td>\n",
       "      <td>510</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Author  No.  Date  PartyID  State  Clean\n",
       "Year1                                          \n",
       "2008      510  510   510      510    510    510\n",
       "2012      178  178   178      178    178    177\n",
       "2016      206  206   206      206    206    206"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rust10_not.groupby('Year1').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rust10_not.to_csv('non_rust_10_ex_180223.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.read_csv('non_rust_10_ex_180223.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rust10.to_csv('clean_rust_10_180223.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rust10_not.to_csv('clean_rust_10_not_180223.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean = pd.read_csv('clean_rust_10_180223.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#t = clean['Clean'].iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#clean[clean['Clean'].str.contains('[applause]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1069\n",
      "178\n",
      "2\n",
      "17\n",
      "53\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "print(len(remarkls))\n",
    "print(len(interviewls))\n",
    "print(len(questionls))\n",
    "print(len(otherls))\n",
    "print(len(speechls))\n",
    "print(len(addressls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(splited_speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = {}\n",
    "for year1, values1 in pe_dict.items():\n",
    "    for author1, values2 in values1.items():\n",
    "        for number, values3 in values2.items():\n",
    "            for num, values4 in values3.items():\n",
    "                #print(values3)\n",
    "                temp.setdefault('Doc.No.', []).append(number)\n",
    "                temp.setdefault('Year1', []).append(year1)\n",
    "                temp.setdefault('Author1', []).append(author1)\n",
    "                temp.setdefault('No.', []).append(num)\n",
    "                for key, value in values4.items():\n",
    "                    temp.setdefault(key, []).append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
