{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_norust_nosw = pd.read_csv('../../Result/STM/alldf_norust_nosw_t45_w15_180302.csv')\n",
    "words_norust_sw = pd.read_csv('../../Result/STM/alldf_norust_sw_t45_w15_180302.csv')\n",
    "words_rust_nosw = pd.read_csv('../../Result/STM/alldf_rust_nosw_t45_w15_180302.csv')\n",
    "words_rust_sw = pd.read_csv('../../Result/STM/alldf_rust_sw_t45_w15_180302.csv')\n",
    "words_rust = pd.read_csv('../../Result/STM/alldf_rust_t45_w15_180302.csv')\n",
    "words_norust = pd.read_csv('../../Result/STM/alldf_norust_t45_w15_180302.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rust_sw = list(words_rust_sw.loc[33])[1:]\n",
    "rust_nosw = list(words_rust_nosw.loc[12])[1:]\n",
    "norust_sw = list(words_norust_sw.loc[35])[1:]\n",
    "norust_nosw = list(words_norust_nosw.loc[4])[1:]\n",
    "words_rust = list(words_rust.loc[43])[1:]\n",
    "words_norust = list(words_norust.loc[12])[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trade', 'agreement', 'nafta', 'worker', 'manufactur', 'china', 'labor', 'deal', 'union', 'plant', 'green', 'steel', 'interest', 'special', 'oversea']\n",
      "['ceo', 'subsidi', 'agreement', 'worker', 'export', 'trade', 'dollar', 'korea', 'crisi', 'propos', 'billion', 'farmer', 'south', 'offer', 'million']\n",
      "['african-american', 'hillari', 'inner', 'clinton', 'islam', 'nafta', 'immigr', 'radic', 'massiv', 'trade', 'terror', 'includ', 'refuge', 'border', 'isi']\n",
      "['latin', 'hemispher', 'cuba', 'cuban', 'religion', 'region', 'colombia', 'castro', 'trade', 'democraci', 'brazil', 'human', 'relationship', 'agreement', 'neighbor']\n",
      "['trade', 'labor', 'worker', 'agreement', 'union', 'nafta', 'china', 'manufactur', 'play', 'plant', 'outsourc', 'wage', 'steel', 'organ', 'green']\n",
      "['african-american', 'hillari', 'clinton', 'inner', 'unleash', 'email', 'nafta', 'disastr', 'donor', 'lie', 'trade', 'massiv', 'oppress', 'rig', 'fail']\n"
     ]
    }
   ],
   "source": [
    "print(rust_sw)\n",
    "print(rust_nosw)\n",
    "print(norust_sw)\n",
    "print(norust_nosw)\n",
    "print(words_rust)\n",
    "print(words_norust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = list(set(rust_sw+rust_nosw+norust_sw+norust_nosw+words_rust+words_norust))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rustbelts = ['New York', 'Pennsylvania', 'West Virginia', 'Ohio', 'Indiana', 'Michigan',\n",
    "             'Illinois', 'Iowa', 'Wisconsin', 'Missouri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rustbelts_ex = ['Pennsylvania', 'West Virginia', 'Ohio', 'Indiana', 'Michigan',\n",
    "             'Illinois', 'Iowa', 'Wisconsin', 'Missouri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dem = ['Barack Obama', 'Hillary Clinton', 'John Edwards', 'Bill Richardson',\n",
    "      'Christopher Dodd', 'Joe Biden', 'Bernie Sanders',  \"Martin O'Malley\", \n",
    "      'Lincoln Chafee', 'Jim Webb']\n",
    "\n",
    "rep = ['John McCain', 'Mike Huckabee', 'Mitt Romney', 'Rudy Giuliani',\n",
    "      'Fred Thompson', 'Ron Paul', 'Newt Gingrich', 'Rick Santorum', 'Rick Perry',\n",
    "      'Jon Huntsman', 'Michele Bachmann', 'Herman Cain', 'Tim Pawlenty',\n",
    "       'Donald J. Trump', 'John Kasich', 'Ted Cruz', 'Marco Rubio', 'Ben Carson',\n",
    "      'Jeb Bush', 'Chris Christie', 'Carly Fiorina', 'Rand Paul', 'George Pataki',\n",
    "      'Lindsey Graham','Scott Walker', 'Bobby Jindal',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmed_stop = list(map(lambda x: re.sub('\\W', '', x), stops))\n",
    "punc = list(map(pt.stem , stemmed_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found directory: ../../Data/\n",
      "../../Data/\n",
      "Found directory: ../../Data/cb_2016_us_state_20m\n",
      "../../Data/cb_2016_us_state_20m\n",
      "Found directory: ../../Data/PE2008\n",
      "../../Data/PE2008\n",
      "Found directory: ../../Data/PE2012\n",
      "../../Data/PE2012\n",
      "Found directory: ../../Data/PE2016\n",
      "../../Data/PE2016\n"
     ]
    }
   ],
   "source": [
    "rootDir = '../../Data/'\n",
    "d = {}\n",
    "remarkls = []\n",
    "interviewls = []\n",
    "questionls = []\n",
    "otherls = []\n",
    "speechls = []\n",
    "addressls = []\n",
    "r = 0\n",
    "i = 0\n",
    "q = 0\n",
    "o = 0\n",
    "s = 0\n",
    "fdls = []\n",
    "pe_dict = {2008:{}, 2012:{}, 2016:{}}\n",
    "for dirName, subdirList, fileList in os.walk(rootDir) :\n",
    "    print('Found directory: %s' % dirName)\n",
    "    print(dirName)\n",
    "    c = 0\n",
    "    for fname in fileList:        \n",
    "        if fname.endswith(\".txt\"):  \n",
    "            filepath = os.path.join(dirName, fname)\n",
    "            if dirName == '../../Data/PE2008':  \n",
    "                c += 1\n",
    "                year = 2008\n",
    "                d = pe_dict[year]\n",
    "                speaker = fname[8:-4]\n",
    "            else:\n",
    "                c += 1\n",
    "                year = fname[8:12]\n",
    "                d = pe_dict[int(year)]\n",
    "                speaker = fname[12:-4]\n",
    "            if speaker in dem:\n",
    "                partyid = 'Dem'\n",
    "            if speaker in rep:\n",
    "                partyid = 'Rep'\n",
    "            d[speaker]={}\n",
    "            with open(filepath, 'r', -1, \"ISO-8859-1\") as input_file:\n",
    "                data = input_file.read()\n",
    "                splited_speeches = data.split('\\n\\n\\n')\n",
    "                #print(splited_speeches)\n",
    "                statement_num = 0\n",
    "                for i in range(len(splited_speeches)):\n",
    "                    statement_num += 1\n",
    "                    one_speech = re.sub(r'\\((?!k\\))(.*?)\\)', '', splited_speeches[i], flags= re.IGNORECASE)\n",
    "                    one_speech_fin = re.sub(r'\\[(.*?)\\]', '', one_speech) \n",
    "                    t = one_speech_fin.replace('\\x80\\x94','').replace('\\x80','')\\\n",
    "                                      .replace('\\x94','').split('\\n')\n",
    "                    text = [item for item in t if item != ''\\\n",
    "                            if not item.startswith('To view')\\\n",
    "                            if not item.startswith('Citation:')]\n",
    "                    whole_text = \" \".join(text[2:])    \n",
    "                    #whole_text5 = re.sub(r'[^\\w\\s]', '',whole_text31.lower())                    \n",
    "                    tokens = nltk.tokenize.word_tokenize(whole_text.lower())\n",
    "                    stemmed_tokens = [pt.stem(w) for w in tokens]\n",
    "                    #punc = [re.sub(r'[^\\w]', '', word.lower()) for word in stops]\n",
    "                    unigrams = [word for word in stemmed_tokens if word not in punc]                    \n",
    "                    fd = nltk.FreqDist(unigrams)\n",
    "                    if text != []:\n",
    "                        title = text[0]\n",
    "                        dateobj = datetime.datetime.strptime(text[1], '%B %d, %Y')\n",
    "                        remarkls.append([speaker, title])\n",
    "                        if 'remarks' in text[0].lower():\n",
    "                            remarkls.append([speaker, title])\n",
    "                            ttype = 'remarks'\n",
    "                        elif 'speech' in text[0].lower():\n",
    "                            speechls.append([speaker, title])\n",
    "                            ttype = 'speech'\n",
    "                        elif 'interview' in text[0].lower():\n",
    "                            interviewls.append([speaker, title])\n",
    "                            ttype = 'interview'\n",
    "                        elif ('question' or 'q&a') in text[0].lower():\n",
    "                            questionls.append([speaker, title])\n",
    "                            ttype = 'question'\n",
    "                        elif 'address' in text[0].lower():\n",
    "                            addressls.append([speaker, title]) \n",
    "                            ttype = 'address'\n",
    "                        else:\n",
    "                            otherls.append([speaker, title])\n",
    "                            ttype = 'others'\n",
    "                                                \n",
    "                        d[speaker][statement_num] = {'Author': speaker, 'Title': title,\n",
    "                                                    'Year':year, 'Whole':splited_speeches[i],\n",
    "                                                     'Clean': whole_text,\n",
    "                                                     'Text': text,\n",
    "                                                     'Date':dateobj,\n",
    "                                                    'Type': ttype,\n",
    "                                                     'PartyID':partyid,\n",
    "                                                    'Length': len(unigrams)}\n",
    "                        \n",
    "                        fdls.append(fd.most_common(10))\n",
    "                        for word in words:\n",
    "                            num = unigrams.count(word)\n",
    "                        #num = len(re.findall(word, speech.lower()))\n",
    "                            d[speaker][statement_num].update({word: num})\n",
    "                    #print(statement_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "swing  = pd.read_excel('../Data/swingstate_2008-2016.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp = {}\n",
    "for year1, values1 in pe_dict.items():\n",
    "    for author1, values2 in values1.items():\n",
    "        for number, values3 in values2.items():\n",
    "            #print(values3)\n",
    "            temp.setdefault('Year1', []).append(year1)\n",
    "            temp.setdefault('Author1', []).append(author1)\n",
    "            temp.setdefault('No.', []).append(number)\n",
    "            for key, value in values3.items():\n",
    "                temp.setdefault(key, []).append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.read_csv('../../Data/pro_state_rust.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge_dtm_fin[['State','pro_rust']].groupby('State').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df08 = df[df['Year1'] == 2008]\n",
    "df12 = df[df['Year1'] == 2012]\n",
    "df16 = df[df['Year1'] == 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f08 = df08[(datetime.datetime(2005, 1, 1, 0, 0) <= df08['Date']) \\\n",
    "           & (df08['Date'] <= datetime.datetime(2008, 12, 31, 0, 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f12 = df12[(datetime.datetime(2009, 1, 1, 0, 0) <= df12['Date']) \\\n",
    "           & (df12['Date'] <= datetime.datetime(2012, 12, 31, 0, 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f16 = df16[(datetime.datetime(2013, 1, 1, 0, 0) <= df16['Date']) \\\n",
    "           & (df16['Date'] <= datetime.datetime(2016, 12, 31, 0, 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refine = pd.concat([f08,f12,f16]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Author', 'Author1', 'Clean', 'Date', 'Length', 'No.',\n",
       "       'PartyID', 'Text', 'Title', 'Type', 'Whole', 'Year', 'Year1',\n",
       "       'african-american', 'agreement', 'billion', 'border', 'brazil',\n",
       "       'castro', 'ceo', 'china', 'clinton', 'colombia', 'crisi', 'cuba',\n",
       "       'cuban', 'deal', 'democraci', 'disastr', 'dollar', 'donor', 'email',\n",
       "       'export', 'fail', 'farmer', 'green', 'hemispher', 'hillari', 'human',\n",
       "       'immigr', 'includ', 'inner', 'interest', 'isi', 'islam', 'korea',\n",
       "       'labor', 'latin', 'lie', 'manufactur', 'massiv', 'million', 'nafta',\n",
       "       'neighbor', 'offer', 'oppress', 'organ', 'outsourc', 'oversea', 'plant',\n",
       "       'play', 'propos', 'radic', 'refuge', 'region', 'relationship',\n",
       "       'religion', 'rig', 'south', 'special', 'steel', 'subsidi', 'terror',\n",
       "       'trade', 'union', 'unleash', 'wage', 'worker'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refine.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refine_fin  = refine[['Author', 'Author1', 'Clean', 'Date', 'Length', 'No.',\n",
    "       'PartyID', 'Text', 'Title', 'Type', 'Whole', 'Year', 'Year1',\n",
    "       'african-american', 'agreement', 'billion', 'border', 'brazil',\n",
    "       'castro', 'ceo', 'china', 'clinton', 'colombia', 'crisi', 'cuba',\n",
    "       'cuban', 'deal', 'democraci', 'disastr', 'dollar', 'donor', 'email',\n",
    "       'export', 'fail', 'farmer', 'green', 'hemispher', 'hillari', 'human',\n",
    "       'immigr', 'includ', 'inner', 'interest', 'isi', 'islam', 'korea',\n",
    "       'labor', 'latin', 'lie', 'manufactur', 'massiv', 'million', 'nafta',\n",
    "       'neighbor', 'offer', 'oppress', 'organ', 'outsourc', 'oversea', 'plant',\n",
    "       'play', 'propos', 'radic', 'refuge', 'region', 'relationship',\n",
    "       'religion', 'rig', 'south', 'special', 'steel', 'subsidi', 'terror',\n",
    "       'trade', 'union', 'unleash', 'wage', 'worker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refine_fin.to_csv('../../Data/df_180306.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdf = pd.read_csv('../../Data/df_180306.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Author', 'Author1', 'Clean', 'Date', 'Length', 'No.',\n",
       "       'PartyID', 'Text', 'Title', 'Type', 'Whole', 'Year', 'Year1',\n",
       "       'african-american', 'agreement', 'billion', 'border', 'brazil',\n",
       "       'castro', 'ceo', 'china', 'clinton', 'colombia', 'crisi', 'cuba',\n",
       "       'cuban', 'deal', 'democraci', 'disastr', 'dollar', 'donor', 'email',\n",
       "       'export', 'fail', 'farmer', 'green', 'hemispher', 'hillari', 'human',\n",
       "       'immigr', 'includ', 'inner', 'interest', 'isi', 'islam', 'korea',\n",
       "       'labor', 'latin', 'lie', 'manufactur', 'massiv', 'million', 'nafta',\n",
       "       'neighbor', 'offer', 'oppress', 'organ', 'outsourc', 'oversea', 'plant',\n",
       "       'play', 'propos', 'radic', 'refuge', 'region', 'relationship',\n",
       "       'religion', 'rig', 'south', 'special', 'steel', 'subsidi', 'terror',\n",
       "       'trade', 'union', 'unleash', 'wage', 'worker'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.read_csv('../../Data/alldf_180223.csv').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covdf = pd.read_csv('../../Data/alldf_covariates2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Year', 'Year1', 'Author', 'Author1', 'Clean', 'Date',\n",
       "       'No.', 'PartyID', 'State', 'Abb', 'Title', 'swing_last_08',\n",
       "       'swing_last_12', 'swing_last_16', 'Rustbelt', 'unemployment',\n",
       "       'challenger', 'governorp', 'primary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adddf = pd.read_excel('../../Data/df18022_addingstate_afternoon.xlsx', sheet_name='df18022_addingstate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Author', 'No.', 'Title', 'Type', 'Year', 'State', 'Abb'], dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adddf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = refine_fin.merge(adddf, left_on=['Author','No.','Year'],\n",
    "                right_on = ['Author','No.','Year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load file contains state information\n",
    "adddf = pd.read_excel('../../Data/df18022_addingstate_afternoon.xlsx', sheet_name='df18022_addingstate')\n",
    "\n",
    "# merge and add state information\n",
    "merged = refine_fin.merge(adddf, left_on=['Author','No.','Year'],\n",
    "                right_on = ['Author','No.','Year'], how='left')\n",
    "\n",
    "addingstatedf = merged[['Author', 'Author1', 'Clean', 'Date', 'Length', 'No.', 'PartyID',\n",
    "       'Text', 'Title_x', 'Type_x', 'Whole', 'Year', 'Year1',\n",
    "       'african-american', 'agreement', 'billion', 'border', 'brazil',\n",
    "       'castro', 'ceo', 'china', 'clinton', 'colombia', 'crisi', 'cuba',\n",
    "       'cuban', 'deal', 'democraci', 'disastr', 'dollar', 'donor', 'email',\n",
    "       'export', 'fail', 'farmer', 'green', 'hemispher', 'hillari', 'human',\n",
    "       'immigr', 'includ', 'inner', 'interest', 'isi', 'islam', 'korea',\n",
    "       'labor', 'latin', 'lie', 'manufactur', 'massiv', 'million', 'nafta',\n",
    "       'neighbor', 'offer', 'oppress', 'organ', 'outsourc', 'oversea', 'plant',\n",
    "       'play', 'propos', 'radic', 'refuge', 'region', 'relationship',\n",
    "       'religion', 'rig', 'south', 'special', 'steel', 'subsidi', 'terror',\n",
    "       'trade', 'union', 'unleash', 'wage', 'worker', 'index', 'Title_y',\n",
    "       'Type_y', 'State', 'Abb']]\n",
    "\n",
    "addstate08 = addingstatedf[addingstatedf['Year1'] == 2008]\n",
    "addstate12 = addingstatedf[addingstatedf['Year1'] == 2012]\n",
    "addstate16 = addingstatedf[addingstatedf['Year1'] == 2016]\n",
    "\n",
    "alldf = pd.concat([addstate08,addstate12,addstate16])\n",
    "\n",
    "# load file contains swing state ratio information\n",
    "swing  = pd.read_excel('../../Data/swingstate_2008-2016.xlsx')\n",
    "sw08 = swing[swing['year'] == 2008]\n",
    "sw12 = swing[swing['year'] == 2012]\n",
    "sw16 = swing[swing['year'] == 2016]\n",
    "\n",
    "# merge with original dataframe and add swing_last ration information\n",
    "statesw08 = alldf.merge(sw08, left_on=['Abb'],right_on = ['state'], how='left')\n",
    "statesw08.rename(columns = {'swing_last':'swing_last_08'}, inplace = True)\n",
    "statesw12 = statesw08.merge(sw12, left_on=['Abb'],right_on = ['state'], how='left')\n",
    "statesw12.rename(columns = {'swing_last':'swing_last_12'}, inplace = True)\n",
    "statesw16 = statesw12.merge(sw16, left_on=['Abb'],right_on = ['state'], how='left')\n",
    "statesw16.rename(columns = {'swing_last':'swing_last_16'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldf_sw = statesw16[['Author', 'Author1', 'Clean', 'Date', 'State',\n",
    "        'Length', 'No.', 'PartyID','Text', 'Title_x', 'Type_x', \n",
    "        'Whole', 'Year', 'Year1', 'african-american', 'agreement',\n",
    "        'billion', 'border', 'brazil', 'castro', 'ceo', 'china', \n",
    "        'clinton', 'colombia', 'crisi', 'cuba',\n",
    "        'cuban', 'deal', 'democraci', 'disastr', 'dollar', 'donor', 'email',\n",
    "        'export', 'fail', 'farmer', 'green', 'hemispher', 'hillari', 'human',\n",
    "        'immigr', 'includ', 'inner', 'interest', 'isi', 'islam', 'korea',\n",
    "        'labor', 'latin', 'lie', 'manufactur', 'massiv', 'million', 'nafta',\n",
    "        'neighbor', 'offer', 'oppress', 'organ', 'outsourc', 'oversea', 'plant',\n",
    "        'play', 'propos', 'radic', 'refuge', 'region', 'relationship',\n",
    "        'religion', 'rig', 'south', 'special', 'steel', 'subsidi', 'terror',\n",
    "        'trade', 'union', 'unleash', 'wage', 'worker', 'index',\n",
    "        'Abb', 'swing_last_08', 'swing_last_12', 'swing_last_16']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misun/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/misun/anaconda/lib/python3.5/site-packages/pandas/core/frame.py:3027: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "alldf_sw ['Rustbelt'] = np.where(alldf_sw[\"State\"].isin(rustbelts_ex), 1, 0)\n",
    "alldf_sw.rename(columns = {'Title_x':'Title', 'Type_x':'Type'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "covdf = pd.read_csv('../../Data/alldf_covariates2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1247, 85)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldf_sw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merge_dtm = covdf.merge(alldf_sw, left_on=['Author','No.','Year','Year1',\n",
    "                                      'Date','PartyID', 'Title'],\n",
    "                             right_on = ['Author','No.','Year','Year1','Date',\n",
    "                                      'PartyID', 'Title'],\n",
    "                            how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Year', 'Year1', 'Author', 'Author1_x', 'Clean_x', 'Date',\n",
       "       'No.', 'PartyID', 'State_x', 'Abb_x', 'Title', 'swing_last_08_x',\n",
       "       'swing_last_12_x', 'swing_last_16_x', 'Rustbelt_x', 'unemployment',\n",
       "       'challenger', 'governorp', 'primary', 'Author1_y', 'Clean_y', 'State_y',\n",
       "       'Length', 'Text', 'Type', 'Whole', 'african-american', 'agreement',\n",
       "       'billion', 'border', 'brazil', 'castro', 'ceo', 'china', 'clinton',\n",
       "       'colombia', 'crisi', 'cuba', 'cuban', 'deal', 'democraci', 'disastr',\n",
       "       'dollar', 'donor', 'email', 'export', 'fail', 'farmer', 'green',\n",
       "       'hemispher', 'hillari', 'human', 'immigr', 'includ', 'inner',\n",
       "       'interest', 'isi', 'islam', 'korea', 'labor', 'latin', 'lie',\n",
       "       'manufactur', 'massiv', 'million', 'nafta', 'neighbor', 'offer',\n",
       "       'oppress', 'organ', 'outsourc', 'oversea', 'plant', 'play', 'propos',\n",
       "       'radic', 'refuge', 'region', 'relationship', 'religion', 'rig', 'south',\n",
       "       'special', 'steel', 'subsidi', 'terror', 'trade', 'union', 'unleash',\n",
       "       'wage', 'worker', 'index', 'Abb_y', 'swing_last_08_y',\n",
       "       'swing_last_12_y', 'swing_last_16_y', 'Rustbelt_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_dtm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misun/anaconda/lib/python3.5/site-packages/pandas/core/frame.py:3027: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "merge_dtm_fin = merge_dtm[['Unnamed: 0', 'index', 'Year', 'Year1', 'Author', 'Author1_x', 'Clean_x', 'Date',\n",
    "       'No.', 'PartyID', 'State_x', 'Abb_x', 'Title', 'swing_last_08_x',\n",
    "       'swing_last_12_x', 'swing_last_16_x', 'Rustbelt_x', 'unemployment',\n",
    "       'challenger', 'governorp', 'primary',\n",
    "       'Length', 'Text', 'Type', 'Whole', 'african-american', 'agreement',\n",
    "       'billion', 'border', 'brazil', 'castro', 'ceo', 'china', 'clinton',\n",
    "       'colombia', 'crisi', 'cuba', 'cuban', 'deal', 'democraci', 'disastr',\n",
    "       'dollar', 'donor', 'email', 'export', 'fail', 'farmer', 'green',\n",
    "       'hemispher', 'hillari', 'human', 'immigr', 'includ', 'inner',\n",
    "       'interest', 'isi', 'islam', 'korea', 'labor', 'latin', 'lie',\n",
    "       'manufactur', 'massiv', 'million', 'nafta', 'neighbor', 'offer',\n",
    "       'oppress', 'organ', 'outsourc', 'oversea', 'plant', 'play', 'propos',\n",
    "       'radic', 'refuge', 'region', 'relationship', 'religion', 'rig', 'south',\n",
    "       'special', 'steel', 'subsidi', 'terror', 'trade', 'union', 'unleash',\n",
    "       'wage', 'worker']]\n",
    "merge_dtm_fin.rename(columns = {'Author1_x':'Author1','Clean_x':'Clean',\n",
    "                                'State_x':'State','Abb_x':'Abb',\n",
    "                                'swing_last_08_x':'swing_last_08',\n",
    "                                'swing_last_12_x':'swing_last_12',\n",
    "                                'swing_last_16_x':'swing_last_16',\n",
    "                                'Rustbelt_x':'Rustbelt'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'Year', 'Year1', 'Author', 'Author1', 'Clean',\n",
       "       'Date', 'No.', 'PartyID', 'State', 'Abb', 'Title', 'swing_last_08',\n",
       "       'swing_last_12', 'swing_last_16', 'Rustbelt', 'unemployment',\n",
       "       'challenger', 'governorp', 'primary', 'Length', 'Text', 'Type', 'Whole',\n",
       "       'african-american', 'agreement', 'billion', 'border', 'brazil',\n",
       "       'castro', 'ceo', 'china', 'clinton', 'colombia', 'crisi', 'cuba',\n",
       "       'cuban', 'deal', 'democraci', 'disastr', 'dollar', 'donor', 'email',\n",
       "       'export', 'fail', 'farmer', 'green', 'hemispher', 'hillari', 'human',\n",
       "       'immigr', 'includ', 'inner', 'interest', 'isi', 'islam', 'korea',\n",
       "       'labor', 'latin', 'lie', 'manufactur', 'massiv', 'million', 'nafta',\n",
       "       'neighbor', 'offer', 'oppress', 'organ', 'outsourc', 'oversea', 'plant',\n",
       "       'play', 'propos', 'radic', 'refuge', 'region', 'relationship',\n",
       "       'religion', 'rig', 'south', 'special', 'steel', 'subsidi', 'terror',\n",
       "       'trade', 'union', 'unleash', 'wage', 'worker'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_dtm_fin.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misun/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/misun/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "merge_dtm_fin['rust_sw_wcsum'] = merge_dtm_fin[rust_sw].sum(axis=1)\n",
    "merge_dtm_fin['rust_nosw_wcsum'] = merge_dtm_fin[rust_nosw].sum(axis=1)\n",
    "merge_dtm_fin['norust_sw_wcsum'] = merge_dtm_fin[norust_sw].sum(axis=1)\n",
    "merge_dtm_fin['norust_nosw_wcsum'] = merge_dtm_fin[norust_nosw].sum(axis=1)\n",
    "merge_dtm_fin['rust_wcsum'] = merge_dtm_fin[words_rust].sum(axis=1)\n",
    "merge_dtm_fin['norust_wcsum'] = merge_dtm_fin[words_norust].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_dtm_fin['pro_rust_sw'] = merge_dtm_fin['rust_sw_wcsum'] / merge_dtm_fin['Length']\n",
    "merge_dtm_fin['pro_rust_nosw'] = merge_dtm_fin['rust_nosw_wcsum'] / merge_dtm_fin['Length']\n",
    "merge_dtm_fin['pro_norust_sw'] = merge_dtm_fin['norust_sw_wcsum'] / merge_dtm_fin['Length']\n",
    "merge_dtm_fin['pro_norust_nosw'] = merge_dtm_fin['norust_nosw_wcsum'] / merge_dtm_fin['Length']\n",
    "merge_dtm_fin['pro_rust'] = merge_dtm_fin['rust_wcsum'] / merge_dtm_fin['Length']\n",
    "merge_dtm_fin['pro_norust'] = merge_dtm_fin['norust_wcsum'] / merge_dtm_fin['Length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merge_dtm_fin.to_csv('../../Data/alldf_w15_180306.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alabama</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arizona</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arkansas</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>california</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colorado</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connecticut</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dc</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>etc</th>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>florida</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreign</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>georgia</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hawaii</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>illinois</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indiana</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iowa</th>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kansas</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kentucky</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louisiana</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maine</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maryland</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>massachusetts</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>michigan</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minnesota</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mississippi</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missouri</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>montana</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nation</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nevada</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new hampshire</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new jersey</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new mexico</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north carolina</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north dakota</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ohio</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oklahoma</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oregon</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pennsylvania</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>puerto rico</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>south carolina</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tennessee</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texas</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utah</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vermont</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginia</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>washington</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>west virginia</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wisconsin</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Year\n",
       "State               \n",
       "alabama            3\n",
       "arizona            6\n",
       "arkansas           1\n",
       "california        25\n",
       "colorado          35\n",
       "connecticut        4\n",
       "dc                77\n",
       "etc              285\n",
       "florida           94\n",
       "foreign           12\n",
       "georgia           10\n",
       "hawaii             1\n",
       "illinois          17\n",
       "indiana           11\n",
       "iowa             102\n",
       "kansas             1\n",
       "kentucky           3\n",
       "louisiana          9\n",
       "maine              2\n",
       "maryland           4\n",
       "massachusetts      4\n",
       "michigan          36\n",
       "minnesota          8\n",
       "mississippi        2\n",
       "missouri          17\n",
       "montana            1\n",
       "multiple          12\n",
       "nation             5\n",
       "nevada            31\n",
       "new hampshire     81\n",
       "new jersey         2\n",
       "new mexico         7\n",
       "new york          37\n",
       "north carolina    29\n",
       "north dakota       2\n",
       "ohio              87\n",
       "oklahoma           1\n",
       "oregon             5\n",
       "pennsylvania      51\n",
       "puerto rico        2\n",
       "south carolina    27\n",
       "tennessee          2\n",
       "texas             13\n",
       "utah               1\n",
       "vermont            2\n",
       "virginia          46\n",
       "washington         1\n",
       "west virginia      7\n",
       "wisconsin         26"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_dtm_fin.groupby('State')['Year'].count().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge_dtm_fin[merge_dtm_fin['State'] == 'utah']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merged = rdf.merge(adddf, left_on=['Author','No.','Year'],\n",
    "#                right_on = ['Author','No.','Year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Author', 'Author1', 'Clean', 'Date', 'No.', 'PartyID',\n",
       "       'Text', 'Title_x', 'Type_x', 'Whole', 'Year', 'Year1', 'index',\n",
       "       'Title_y', 'Type_y', 'State', 'Abb'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#swing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sw08 = swing[swing['year'] == 2008]\n",
    "sw12 = swing[swing['year'] == 2012]\n",
    "sw16 = swing[swing['year'] == 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addingstatedf = merged[['Unnamed: 0', 'Author', 'Author1', 'Clean', 'Date', 'No.', 'PartyID',\n",
    "                        'State','Abb','Text', 'Title_x', 'Type_x', 'Whole', 'Year', 'Year1', \n",
    "                        'index','Title_y', 'Type_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addstate08 = addingstatedf[addingstatedf['Year1'] == 2008]\n",
    "addstate12 = addingstatedf[addingstatedf['Year1'] == 2012]\n",
    "addstate16 = addingstatedf[addingstatedf['Year1'] == 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldf = pd.concat([addstate08,addstate12,addstate16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statesw08 = alldf.merge(sw08, left_on=['Abb'],right_on = ['state'], how='left')\n",
    "statesw08.rename(columns = {'swing_last':'swing_last_08'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statesw12 = statesw08.merge(sw12, left_on=['Abb'],right_on = ['state'], how='left')\n",
    "statesw12.rename(columns = {'swing_last':'swing_last_12'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statesw16 = statesw12.merge(sw16, left_on=['Abb'],right_on = ['state'], how='left')\n",
    "statesw16.rename(columns = {'swing_last':'swing_last_16'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldf_sw = statesw16[['Year', 'Year1', 'Author', 'Author1', 'Clean', 'Date', 'No.', 'PartyID',\n",
    "       'State', 'Abb', 'Title_x', 'swing_last_08', 'swing_last_12', 'swing_last_16']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misun/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "alldf_sw ['Rustbelt'] = np.where(alldf_sw[\"State\"].isin(rustbelts_ex), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misun/anaconda/lib/python3.5/site-packages/pandas/core/frame.py:3027: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "alldf_sw.rename(columns = {'Title_x':'Title'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Year1', 'Author', 'Author1', 'Clean', 'Date', 'No.', 'PartyID',\n",
       "       'State', 'Abb', 'Title', 'swing_last_08', 'swing_last_12',\n",
       "       'swing_last_16', 'Rustbelt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldf_sw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldf_sw.to_csv('../Data/alldf_180226.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.read_csv('alldf_180223.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(685, 18)\n",
      "(282, 18)\n",
      "(280, 18)\n",
      "(685, 23)\n",
      "(282, 23)\n",
      "(280, 23)\n"
     ]
    }
   ],
   "source": [
    "print(addstate08.shape)\n",
    "print(addstate12.shape)\n",
    "print(addstate16.shape)\n",
    "print(statesw08.shape)\n",
    "print(statesw12.shape)\n",
    "print(statesw16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rust10 = findf[findf['State'].isin(rustbelts_ex)][['Author','Year1','No.','Date',\n",
    "                                                'PartyID','State','Clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rust10_not = findf[~findf['State'].isin(rustbelts_ex)][['Author','Year1','No.','Date',\n",
    "                                                        'PartyID','State','Clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>No.</th>\n",
       "      <th>Date</th>\n",
       "      <th>PartyID</th>\n",
       "      <th>State</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>510</td>\n",
       "      <td>510</td>\n",
       "      <td>510</td>\n",
       "      <td>510</td>\n",
       "      <td>510</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Author  No.  Date  PartyID  State  Clean\n",
       "Year1                                          \n",
       "2008      510  510   510      510    510    510\n",
       "2012      178  178   178      178    178    177\n",
       "2016      206  206   206      206    206    206"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rust10_not.groupby('Year1').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rust10_not.to_csv('non_rust_10_ex_180223.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.read_csv('non_rust_10_ex_180223.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rust10.to_csv('clean_rust_10_180223.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rust10_not.to_csv('clean_rust_10_not_180223.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean = pd.read_csv('clean_rust_10_180223.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#t = clean['Clean'].iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#clean[clean['Clean'].str.contains('[applause]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1069\n",
      "178\n",
      "2\n",
      "17\n",
      "53\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "print(len(remarkls))\n",
    "print(len(interviewls))\n",
    "print(len(questionls))\n",
    "print(len(otherls))\n",
    "print(len(speechls))\n",
    "print(len(addressls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(splited_speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = {}\n",
    "for year1, values1 in pe_dict.items():\n",
    "    for author1, values2 in values1.items():\n",
    "        for number, values3 in values2.items():\n",
    "            for num, values4 in values3.items():\n",
    "                #print(values3)\n",
    "                temp.setdefault('Doc.No.', []).append(number)\n",
    "                temp.setdefault('Year1', []).append(year1)\n",
    "                temp.setdefault('Author1', []).append(author1)\n",
    "                temp.setdefault('No.', []).append(num)\n",
    "                for key, value in values4.items():\n",
    "                    temp.setdefault(key, []).append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
